# Two experiments:
#
# One "normal" IGTree experiment.
# One word expert experiment (IB1, IGT, etc).
# Compare the two output files.
#
# wopr -s this.script -p filename:nyt.1e5,
#                        focus:nyt.1e5.lex.r10n100,
#                        testfile:nyt.tail1000
#
#params:filename:GIVEN
#params:focus:GIVEN
#params:testfile:GIVEN
#
params: topn:5
params: rc:0
params: lc:3
#
# Prepare testset first
#
set:saved_filename:$filename
set: filename:$testfile
run:window_lr
set:testfile:$filename
#
# Set filename again, prepare data/sets
#
set:filename:$saved_filename
#msg: filename = $filename and save_filename= $saved_filename
run:lexicon
run:window_lr
#this filename/dataset we need later on.
set:saved_filename:$filename
#
# Experiment 1, IGT, pplx
#
params: timbl:-a1 +D
run: make_ibase
# restore testfile
set:filename:$testfile
run:pplxs
#
# Experiment 2, WEP
#
#restore filename
set:filename:$saved_filename
params: timbl:-a0 +D
params: fco:1
# NB: we take fcm 2 now, so we can re-use our full
# default classifier without training all the unused
# left over databases.
params: fcm:2
params: nf:0
run:focus
# restore testfile
set:filename:$testfile
run:mg
